<!DOCTYPE html>
<html lang="en-US">
  <head>

    
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Trustworthy and Socially Responsible Machine Learning | Workshop at NeurIPS 2022</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Trustworthy and Socially Responsible Machine Learning" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Trustworthy and Socially Responsible Machine Learning | Workshop at NeurIPS 2022" />
<meta property="og:description" content="Trustworthy and Socially Responsible Machine Learning | Workshop at NeurIPS 2022" />
<meta property="og:site_name" content="Trustworthy and Socially Responsible Machine Learning" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Trustworthy and Socially Responsible Machine Learning" />
<script type="application/ld+json">
{"headline":"Trustworthy and Socially Responsible Machine Learning","url":"/","name":"Trustworthy and Socially Responsible Machine Learning","description":"Trustworthy and Socially Responsible Machine Learning | Workshop at NeurIPS 2022","@type":"WebSite","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="/assets/css/style.css?v=">
  </head>
  <body>
    <a id="skip-to-content" href="#content">Skip to the content.</a>

    <header class="page-header" role="banner">
      <h1 class="project-name">Trustworthy and Socially Responsible <br> Machine Learning (TSRML)</h1>
      <h2 class="project-tagline">Workshop at <a href="https://neurips.cc/">NeurIPS 2022</a><br> Virtual, December 9, 2022</h2>
      
      
      <a href="/" class="btn">Home</a>
      
      <a href="/cfp" class="btn">Call for Papers</a>
      
      <a href="/papers" class="btn">Accepted Papers</a>
      
      <a href="/schedule" class="btn">Schedule</a>
      
      <a href="/speakers" class="btn">Speakers</a>
      
      <a href="/organizers" class="btn">Organizers</a>
      
      <a href="/committee" class="btn">Program Committee</a>
      
      <a href="/related" class="btn">Related Workshops</a>
      
    </header>

    <main id="content" class="main-content" role="main">
      <h1 id="overview">Overview</h1>

<table>
  <tbody>
    <tr>
      <td><strong>Date</strong></td>
      <td>December 9, 2022</td>
      <td><strong>Location</strong></td>
	    <td>Virtual</td>
      <td><strong>Link</strong></td>
      <td><a href="https://neurips.cc/virtual/2022/workshop/49959">neurips.cc/virtual/2022/workshop/49959</a></td>
<!--       <td>The workshop will be held <em>virtually</em>. The internal NeurIPS workshop website is <a href="https://iclr.cc/virtual/2021/workshop/2127">here</a> (NeurIPS registration required).</td> -->
    </tr>
  </tbody>
</table>


<p>To attend the workshop, a Virtual Only Pass registration or any form of physical registration (either Conference or Workshop or both) at NeurIPS 2022 following this <a href="https://neurips.cc/Register">link</a> is needed.</p>

<hr>

<p>While machine learning (ML) models have achieved great success in many applications, concerns have been raised about their potential security, privacy, fairness, transparency and ethics issues when applied to real-world applications. Irresponsibly applying machine learning to mission-critical and human-centric domains such as healthcare, education, and law can lead to serious misuse, inequity issues, negative economic and environmental impacts, and/or legal and ethical concerns.</p>

<p>To address these negative societal impacts of ML, researchers have looked into different principles and constraints to ensure trustworthy and socially responsible machine learning systems. This workshop makes the first attempt towards bridging the gap between security, privacy, fairness, ethics, game theory, and machine learning communities and aims to discuss the principles and experiences of developing trustworthy and socially responsible machine learning systems. The workshop also focuses on how future researchers and practitioners should prepare themselves for reducing the risks of unintended behaviors of sophisticated ML models.</p>

<p>This workshop aims to bring together researchers interested in the emerging and interdisciplinary field of trustworthy and socially responsible machine learning from a broad range of disciplines with different perspectives to this problem. We attempt to highlight recent related work from different communities, clarify the foundations of trustworthy machine learning, and chart out important directions for future work and cross-community collaborations. Topics of this workshop include but are not limited to:</p>

<ul>
<li>Novel methods for building more trustworthy machine learning models that prevent or alleviate negative societal impacts of existing ML methods</li>
<li>New applications and settings where trustworthiness of machine learning plays an important role and how well existing techniques work under these settings</li>
<li>Machine learning models with verifiable guarantees (such as robustness, fairness and privacy guarantees) to build trustworthiness</li>
<li>Privacy-preserving machine learning approaches</li>
<li>Theoretical understanding of trustworthy machine learning</li>
<li>Explainable and interpretable AI</li>
<li>Robust decision making under uncertainty</li>
<li>Futuristic concerns about trustworthy machine learning</li>
<li>Game-theoretic analysis for socially responsible machine learning systems</li>
<li>Case studies and field research of the societal impacts of applying machine learning in mission-critical and human-centric tasks</li>
</ul>

<h3>In-person Meet-up in NYC</h3>

<p>For participants of the TSRML workshop in the evening after its conclusion, on December 9 around 8:00pm ET, we will have an in-person meet-up in NYC.</p>

<p>The tentative venue is Peter McManus Cafe (a casual Irish-style pub), located at 152 7th Ave, New York, NY 10011. </p>
  
<p>Please make a note of your interest using <a href="https://docs.google.com/forms/d/e/1FAIpQLScXPpyBUu1fitACTpnxkdnF3VfC-cNFwisIhMfDH6vrffrqXw/viewform">this form</a> so that we can communicate logistics and update to an appropriately sized venue, if needed. You can also direct any questions to Melissa Hall via the last option in the form. Looking forward to meeting you who are interested and active in this space!</p>

<p>Thanks to <a href="http://melissa-hall.com/">Melissa Hall</a> for making this happen!</p>

<h1 id="schedule">Featured Speakers</h1>

<p>Ordered alphabetically by last name.</p>

<table>
  <tbody>
    <tr>
      <td><img src="./assets/images/kamalika.jpeg" alt="Kamalika Chaudhuri" width="225" /></td>
      <td><img src="./assets/images/nika.jpg" alt="Nika Haghtalab" width="225" /></td>
      <!-- <td><img src="./assets/images/somesh.jpeg" alt="Somesh Jha" width="180" /></td> -->
      <td><img src="./assets/images/Been_Kim.png" alt="Been Kim" width="225" /></td>
      <td><img src="./assets/images/YiMa.jpg" alt="Yi Ma" width="225" /></td>
    </tr>
    <tr>
      <td width="225" ><a href="https://cseweb.ucsd.edu/~kamalika/">Kamalika Chaudhuri</a><br />University of California, San Diego</td>
      <td width="225" ><a href="https://people.eecs.berkeley.edu/~nika/">Nika Haghtalab</a><br />University of California, Berkeley</td>
      <!-- <td width="180" ><a href="https://pages.cs.wisc.edu/~jha/">Somesh Jha</a><br />University of Wisconsin-Madison</td> -->
      <td width="225" ><a href="https://beenkim.github.io/">Been Kim</a><br />Google Brain</td>
      <td width="225" ><a href="https://people.eecs.berkeley.edu/~yima/">Yi Ma</a><br />University of California, Berkeley</td>
    </tr>

    <tr>
      <td><img src="./assets/images/Aleksander_Madry.png" alt="Aleksander Mądry" width="225" /></td>
      <td><img src="./assets/images/marco.jpg" alt="Marco Pavone" width="225" /></td>
      <!-- <td><img src="./assets/images/radha.jpg" alt="Radha Poovendran" width="180"/></td> -->
      <td><img src="./assets/images/dorsa.jpg" alt="Dorsa Sadigh" width="225"/></td>
      <td><img src="./assets/images/milind.jpeg" alt="Milind Tambe" width="225"/></td>
    </tr>
    <tr>
      <td width="225" ><a href="https://madry.mit.edu/">Aleksander Mądry</a><br />Massachusetts Institute of Technology</td>
      <td width="225" ><a href="https://profiles.stanford.edu/marco-pavone">Marco Pavone</a><br />Stanford University</td>
      <!-- <td width="180" ><a href="https://people.ece.uw.edu/radha/index.html">Radha Poovendran</a><br />University of Washington</td> -->
      <td width="225" ><a href="https://dorsa.fyi/">Dorsa Sadigh</a><br />Stanford University</td>
      <td width="225" ><a href="https://teamcore.seas.harvard.edu/tambe">Milind Tambe</a><br />Harvard University</td>
    </tr>
  </tbody>
</table>

<h1 id="panelist">Panelists</h1>

<p>Ordered alphabetically by last name.</p>

<table>
  <tbody>
    <tr>
      <td><img src="./assets/images/kamalika.jpeg" alt="Kamalika Chaudhuri" width="225" /></td>
      <td><img src="./assets/images/Been_Kim.png" alt="Been Kim" width="225" /></td>
      <td><img src="./assets/images/dorsa.jpg" alt="Dorsa Sadigh" width="225"/></td>
    </tr>
    <tr>
      <td width="225" ><a href="https://cseweb.ucsd.edu/~kamalika/">Kamalika Chaudhuri</a><br />University of California, San Diego</td>
      <td width="225" ><a href="https://beenkim.github.io/">Been Kim</a><br />Google Brain</td>
      <td width="225" ><a href="https://dorsa.fyi/">Dorsa Sadigh</a><br />Stanford University</td>
    </tr>
  </tbody>
</table>



<h1 id="paper-awards">Paper Awards</h1>

<h2 id="best-paper-award">Outstanding Paper Award</h2>

<ul>
  <li>
    <b><a href="https://openreview.net/forum?id=25Fc-EEUSt">Controllable Attack and Improved Adversarial Training in Multi-Agent Reinforcement Learning</a></b> <br /> 
    Xiangyu Liu; Souradip Chakraborty; Furong Huang
  </li>
  <li>
    <b><a href="https://openreview.net/forum?id=6Bo1vhoHolh">Differentially Private Bias-Term only Fine-tuning of Foundation Models</a></b> <br />
    Zhiqi Bu; Yu-Xiang Wang; Sheng Zha; George Karypis
  </li>

  <li>
    <b><a href="https://openreview.net/forum?id=EIJ2TkmkPNB">zPROBE: Zero Peek Robustness Checks for Federated Learning</a></b> <br /> 
    Zahra Ghodsi; Mojan Javaheripi; Nojan Sheybani; Xinqiao Zhang; Ke Huang; Farinaz Koushanfar
  </li>
</ul>

<h2 id="best-paper-honorable-mention-award">Oral</h2>

<ul>
  <li>
    <b><a href="https://openreview.net/forum?id=lxFHe7CnRY">Revisiting Robustness in Graph Machine Learning</a></b> <br /> 
    Lukas Gosch; Daniel Sturm; Simon Geisler; Stephan Günnemann
  </li>

  <li>
    <b><a href="https://openreview.net/forum?id=4GI04owSZk8">DensePure: Understanding Diffusion Models towards Adversarial Robustness</a></b> <br /> 
    Zhongzhu Chen; Kun Jin; Jiongxiao Wang; Weili Nie; Mingyan Liu; Anima Anandkumar; Bo Li; Dawn Song
  </li>

  <li>
    <b><a href="https://openreview.net/forum?id=cSiFMffu3yw">TalkToModel: Explaining Machine Learning Models with Interactive Natural Language Conversations</a></b> <br /> 
    Dylan Z Slack; Satyapriya Krishna; Himabindu Lakkaraju; Sameer Singh
  </li>
</ul>

<h2 id="organizers">Organizers</h2>

<table>
  <tbody>
    <tr>
      <td><img src="./assets/images/huan.jpg" alt="Huan Zhang" width="300" /></td>
      <td><img src="./assets/images/linyi.jpg" alt="Linyi Li" width="300" /></td>
      <td><img src="./assets/images/chaowei.jpg" alt="Chaowei Xiao" width="300" /></td>
    </tr>
    <tr>
      <td width="300" ><a href="https://huan-zhang.com/">Huan Zhang</a><br />Carnegie Mellon University</td>
      <td width="300" ><a href="http://linyil.com/">Linyi Li</a><br />University of Illinois Urbana-Champaign</td>
      <td width="300" ><a href="https://xiaocw11.github.io/">Chaowei Xiao</a><br />Arizona State University & NVIDIA</td>
    </tr>

    <tr>
      <td><img src="./assets/images/zicokolter.jpg" alt="Zico Kolter" width="300" /></td>
      <td><img src="./assets/images/anima.jpg" alt="Anima Anandkumar" width="300" /></td>
      <td><img src="./assets/images/bo_li.jpg" alt="Bo Li" width="300"/></td>
    </tr>
    <tr>
      <td width="300" ><a href="https://zicokolter.com/">Zico Kolter</a><br />Carnegie Mellon University</td>
      <td width="300" ><a href="http://tensorlab.cms.caltech.edu/users/anima/index.html">Anima Anandkumar</a><br />California Institute of Technology & NVIDIA</td>
      <td width="300" ><a href="https://aisecure.github.io/">Bo Li</a><br />University of Illinois Urbana-Champaign</td>
    </tr>
  </tbody>
</table>


<h4>Diversity Statement</h4>
We organizers are committed to ensuring fairness and equality to all who attend, submit to, and review for the workshop. 
Our goal is to create a forum that fosters inclusion for all as we strive to build a supportive community for those who participate. All suggestions are encouraged and appreciated as we move forward.
For examples, we have taken various steps to expand the diversity of the participants:
The organizers and invited speakers have diverse backgrounds (e.g., gender, race, affiliations, seniority, and nationality). In particular, many are from underrepresented groups in STEM fields: the organizers include female scholars and the confirmed speakers include female scholars as well as researchers from underrepresented races. 
<!-- The organizers include both experienced and senior members as well as junior researchers, including people who have not organized this workshop series. Moreover, The workshop encompasses researchers from both industry and academia. -->
Additionally, the workshop is inclusive and covers a wide range of topics (e.g., fairness, transparency, interpretability, privacy, robustness, etc).
<!-- , which has raised a lot of attention now. We also aim to bring together both theoretical and applied researchers from various domains. -->

      <footer class="site-footer">
        <span class="site-footer-credits">
          <!-- Please contact <a href="mailto:huan@huan-zhang.com">Huan Zhang</a> or <a href="mailto:linyi2@illinois.edu">Linyi Li</a> if you have any questions.<br> -->
          If you have any questions, please contact the organizers via <a href="mailto:tsrml2022@googlegroups.com">tsrml2022@googlegroups.com</a>.<br>
          This page was generated by <a href="https://pages.github.com">GitHub Pages</a> following the template of <a href="https://aisecure-workshop.github.io/aml-iclr2021">AML-ICLR 2021 workshop</a>.
        </span>
      </footer>
    </main>
  </body>
</html>
