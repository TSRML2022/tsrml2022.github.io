<!DOCTYPE html>
<html lang="en-US">
  <head>

    
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Trustworthy and Socially Responsible Machine Learning | Workshop at NeurIPS 2022</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Trustworthy and Socially Responsible Machine Learning" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Trustworthy and Socially Responsible Machine Learning | Workshop at NeurIPS 2022" />
<meta property="og:description" content="Trustworthy and Socially Responsible Machine Learning | Workshop at NeurIPS 2022" />
<meta property="og:site_name" content="Trustworthy and Socially Responsible Machine Learning" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Trustworthy and Socially Responsible Machine Learning" />
<script type="application/ld+json">
{"headline":"Trustworthy and Socially Responsible Machine Learning","url":"/schedule.html","description":"Trustworthy and Socially Responsible Machine Learning | Workshop at NeurIPS 2022","@type":"WebPage","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="/assets/css/style.css?v=">
  </head>
  <body>
    <a id="skip-to-content" href="#content">Skip to the content.</a>

    <header class="page-header" role="banner">
      <h1 class="project-name">Trustworthy and Socially Responsible <br> Machine Learning (TSRML)</h1>
      <h2 class="project-tagline">Workshop at <a href="https://neurips.cc/">NeurIPS 2022</a><br> Virtual, December 9, 2022</h2>
      
      
      <a href="/" class="btn">Home</a>
      
      <a href="/cfp" class="btn">Call for Papers</a>
      
      <a href="/papers" class="btn">Accepted Papers</a>
      
      <a href="/schedule" class="btn">Schedule</a>
      
      <a href="/speakers" class="btn">Speakers</a>
      
      <a href="/organizers" class="btn">Organizers</a>
      
      <a href="/committee" class="btn">Program Committee</a>
      
      <a href="/related" class="btn">Related Workshops</a>
      
    </header>

    <main id="content" class="main-content" role="main">
      <h1 id="schedule">Speakers</h1>

<p>Speakers are in alphabetical order by last name.</p>

<table>
  <tbody>
    <tr>
      <td><img src="./assets/images/kamalika.jpeg" alt="Kamalika Chaudhuri" width="225" /></td>
      <td><img src="./assets/images/nika.jpg" alt="Nika Haghtalab" width="225" /></td>
      <!-- <td><img src="./assets/images/somesh.jpeg" alt="Somesh Jha" width="180" /></td> -->
      <td><img src="./assets/images/Been_Kim.png" alt="Been Kim" width="225" /></td>
      <td><img src="./assets/images/YiMa.jpg" alt="Yi Ma" width="225" /></td>
    </tr>
    <tr>
      <td width="225" ><a href="https://cseweb.ucsd.edu/~kamalika/">Kamalika Chaudhuri</a><br />University of California, San Diego</td>
      <td width="225" ><a href="https://people.eecs.berkeley.edu/~nika/">Nika Haghtalab</a><br />University of California, Berkeley</td>
      <!-- <td width="180" ><a href="https://pages.cs.wisc.edu/~jha/">Somesh Jha</a><br />University of Wisconsin-Madison</td> -->
      <td width="225" ><a href="https://beenkim.github.io/">Been Kim</a><br />Google Brain</td>
      <td width="225" ><a href="https://people.eecs.berkeley.edu/~yima/">Yi Ma</a><br />University of California, Berkeley</td>
    </tr>

    <tr>
      <td><img src="./assets/images/Aleksander_Madry.png" alt="Aleksander Mądry" width="225" /></td>
      <td><img src="./assets/images/marco.jpg" alt="Marco Pavone" width="225" /></td>
      <!-- <td><img src="./assets/images/radha.jpg" alt="Radha Poovendran" width="180"/></td> -->
      <td><img src="./assets/images/dorsa.jpg" alt="Dorsa Sadigh" width="225"/></td>
      <td><img src="./assets/images/milind.jpeg" alt="Milind Tambe" width="225"/></td>
    </tr>
    <tr>
      <td width="225" ><a href="https://madry.mit.edu/">Aleksander Mądry</a><br />Massachusetts Institute of Technology</td>
      <td width="225" ><a href="https://profiles.stanford.edu/marco-pavone">Marco Pavone</a><br />Stanford University</td>
      <!-- <td width="180" ><a href="https://people.ece.uw.edu/radha/index.html">Radha Poovendran</a><br />University of Washington</td> -->
      <td width="225" ><a href="https://dorsa.fyi/">Dorsa Sadigh</a><br />Stanford University</td>
      <td width="225" ><a href="https://teamcore.seas.harvard.edu/tambe">Milind Tambe</a><br />Harvard University</td>
    </tr>
  </tbody>
</table>

<h2>Talk Abstracts</h2>

  <h4>Dorsa Sadigh (14:30 - 15:00): Aligning Robot Representations with Humans</h4>

  Aligning robot objectives with human preferences is a key challenge in robot learning. In this talk, I will start with discussing how active learning of human preferences can effectively query humans with the most informative questions to learn their preference reward functions. I will discuss some of the limitations of prior work, and how approaches such as few-shot learning can be integrated with active preference based learning for the goal of reducing the number of queries to a human expert and allowing for truly bringing in humans in the loop of learning neural reward functions. I will then talk about how we could go beyond active learning from a single human, and tap into large language models (LLMs) as another source of information to capture human preferences that are hard to specify. I will discuss how LLMs can be queried within a reinforcement learning loop and help with reward design. Finally I will discuss how the robot can also provide useful information to the human and be more transparent about its learning process. We demonstrate how the robot’s transparent behavior would guide the human to provide compatible demonstrations that are more useful and informative for learning.

  <h4>Marco Pavone (15:00 - 15:30): Run-time monitoring for safe robot autonomy</h4>

  <p>In this talk I will present our recent results towards designing run-time monitors that can equip any pre-trained deep neural network with a task-relevant epistemic uncertainty estimate. I will show how run-time monitors can be used to identify, in real-time, anomalous inputs and, more broadly, provide safety assurances for learning-based autonomy stacks. Finally, I will discuss how run-time monitors can also be used to devise effective strategies for data lifecycle management.</p>


      <footer class="site-footer">
        <span class="site-footer-credits">
          <!-- Please contact <a href="mailto:huan@huan-zhang.com">Huan Zhang</a> or <a href="mailto:linyi2@illinois.edu">Linyi Li</a> if you have any questions.<br> -->
          If you have any questions, please contact the organizers via <a href="mailto:tsrml2022@googlegroups.com">tsrml2022@googlegroups.com</a>.<br>
          This page was generated by <a href="https://pages.github.com">GitHub Pages</a> following the template of <a href="https://aisecure-workshop.github.io/aml-iclr2021">AML-ICLR 2021 workshop</a>.
        </span>
      </footer>
    </main>
  </body>
</html>
